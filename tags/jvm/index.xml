<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Pelure</title>
  <link href="http://hugoduncan.org/index.xml" rel="self"/>
  <link href="http://hugoduncan.org/"/>
  <updated>2021-11-22T02:39:16+00:00</updated>
  <id>http://hugoduncan.org/</id>
  <author>
    <name>Hugo Duncan</name>
  </author>
  <entry>
    <id>http://hugoduncan.org/post/benchmarking_clojure_code_with_criterium.html</id>
    <link href="http://hugoduncan.org/post/benchmarking_clojure_code_with_criterium.html"/>
    <title>Benchmarking Clojure Code with Criterium</title>
    <summary>I have released Criterium, a new project for benchmarking code in Clojure.  I found Brent Broyer's article on Java benchmarking which explains many of the pitfalls of benchmarking on the JVM, and Criterion, a benchmarking library in Haskell.</summary>
    <updated>2010-02-19T23:59:59+00:00</updated>
    <content type="html">
      <![CDATA[<p><p>I have released <a href="http://github.com/hugoduncan/criterium">Criterium</a>, a new project for benchmarking code in <a href="http://clojure.org">Clojure</a>.  I found Brent Broyer's <a href="http://www.ibm.com/developerworks/java/library/j-benchmark1.html">article on Java benchmarking</a> which explains many of the pitfalls of benchmarking on the JVM, and <a href="http://www.serpentine.com/blog/2009/09/29/criterion-a-new-benchmarking-library-for-haskell">Criterion</a>, a benchmarking library in Haskell.</p></p><p><p>The main issues with benchmarking on the JVM are associated with garbage collection, and with JIT compilation.  It seems from Broyer's articles that we can mitigate the effects but not completely eliminate them, and Criterium follows his advice.  Both of the above libraries use the <a href="http://en.wikipedia.org/wiki/Bootstrapping_(statistics)">bootstrap</a> technique to estimate mean execution time and provide a confidence interval, and Criterium does likewise.  At the moment the confidence intervals are biased and I still need to implement BCa or ABC to improve these.</p></p><p><p>One of the functions that I wanted to benchmark originally involved reading a file.  Criterium does not yet address clearing I/O buffer cache, and I am not sure on the best way forward on this.  On Mac OS X, the <code>purge</code> command can be used to clear the caches, and on Linux this can be achieved by writing to /proc/sys/vm/drop_caches.  On the Mac at least, this causes everything to grind to halt for about five seconds, and there are then some file reads as whatever processes are running read things in again. This sort of behaviour doesn't lend itself to inclusion in a timing loop... Any suggestions?</p></p>]]>
    </content>
  </entry>
</feed>
